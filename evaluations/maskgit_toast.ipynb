{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "device=\"cuda:0\"\n",
    "from imagenet_dict import imagenet_dict\n",
    "from muse.pipeline_muse_toast import PipelineMuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_intermediate_img_and_mask(i_batch, timestep, images, intermediate_images, mask_index, res=256):\n",
    "    seq_len = 16 if res == 256 else 32\n",
    "    vq_len = 256 if res == 256 else 1024\n",
    "    inter_arr = [np.array(intermediate_images[i][i_batch]) for i in range(timestep)]\n",
    "    mask_arr = [np.array(mask_index[i][i_batch].reshape(-1, seq_len, seq_len).squeeze().detach().cpu()) for i in range(timestep)]\n",
    "\n",
    "    fig, axes = plt.subplots(timestep+1, 3, figsize=(10, (timestep+2)*2))\n",
    "\n",
    "    mask_arr_np = np.concatenate([np.zeros((1,seq_len,seq_len)), 1-np.array(mask_arr)])\n",
    "    for i in range(timestep):\n",
    "        previous = mask_arr_np[i]\n",
    "        now = mask_arr_np[i+1]\n",
    "        approved = previous * now\n",
    "        created = now - approved\n",
    "        denied = previous - approved\n",
    "        image_rgb = np.zeros((seq_len, seq_len, 3))\n",
    "        image_rgb[created == 1] = [0, 1, 1]  # Sky Blue for created\n",
    "        image_rgb[approved == 1] = [0, 1, 0]  # Green for approved\n",
    "        image_rgb[denied == 1] = [1, 0, 0]  # Red for denied\n",
    "        \n",
    "        axes[i][0].imshow(inter_arr[i], interpolation='nearest', aspect='equal')\n",
    "        axes[i][1].matshow(1-mask_arr[i], cmap='gray')\n",
    "        axes[i][2].imshow(image_rgb, interpolation='nearest', aspect='equal')\n",
    "        \n",
    "        axes[i][0].axis(\"off\")\n",
    "        axes[i][1].axis(\"off\")\n",
    "        axes[i][2].axis(\"off\")\n",
    "        \n",
    "        # Insert the count of approved pixels between the subplots\n",
    "        unmasked = now.sum() / vq_len\n",
    "        prev_unmasked = previous.sum() / vq_len\n",
    "        approved = approved.sum() / vq_len\n",
    "        denied = denied.sum() / vq_len\n",
    "        created = created.sum() / vq_len\n",
    "        txt = f'prev_unmasked: {prev_unmasked:.2f} || unmasked: {unmasked:.2f} || approved: {approved:.2f} || denied: {denied:.2f} || created: {created:.2f}'\n",
    "        \n",
    "        axes[i][1].text(0.5, 1.05, txt, \n",
    "                        horizontalalignment='center', \n",
    "                        verticalalignment='center', \n",
    "                        transform=axes[i][1].transAxes)\n",
    "\n",
    "    axes[timestep][0].imshow(images[i_batch], interpolation='nearest', aspect='equal')\n",
    "    axes[timestep][0].axis(\"off\")\n",
    "    axes[timestep][1].axis(\"off\")\n",
    "    axes[timestep][2].axis(\"off\")\n",
    "        \n",
    "    fig.tight_layout() \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = PipelineMuse.from_pretrained(transformer_path=\"../results_corr/ft_256_toast_cls_b256_corr/checkpoint-50000/ema_model\", \n",
    "                                    is_class_conditioned=True, use_toast=True, vae_path=\"../scripts/tokenizer_imagenet256_torch/\").to(device)\n",
    "# pipe = PipelineMuse.from_pretrained(transformer_path=\"../results_corr/ft_512_toast_cls_b256_corr/checkpoint-50000/ema_model\", \n",
    "#                                     is_class_conditioned=True, use_toast=True, vae_path=\"../scripts/tokenizer_imagenet512_torch/\").to(device)\n",
    "pipe.transformer.eval()\n",
    "pipe.vae.eval()\n",
    "print(\"Loaded model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scene class id of Imagenet\n",
    "\n",
    "class_ids = 105 # 105: koala 454: bookstore\n",
    "\n",
    "timesteps = 18\n",
    "images, intermediate_images, intermediate, mask_index = pipe(class_ids=class_ids, num_images_per_prompt=4, \n",
    "                                   timesteps=timesteps, temperature=10, sampling_type='self_guidance', #maskgit or self_guidance\n",
    "                                   return_intermediate=True, guidance_scale=1.0)\n",
    "print(imagenet_dict[class_ids])\n",
    "for i in range(4):\n",
    "    display(images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_batch = 0\n",
    "display_intermediate_img_and_mask(i_batch, timesteps, images, intermediate_images, mask_index, res=256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50dd96137dc1217dbb5a4b77b01cf18314368902f96ea7b6b16b7f34afe8268a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
